<!-- HTML header for doxygen 1.9.6-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
  <head>
    <meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=11" />
    <meta name="generator" content="Doxygen 1.10.0" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>Iros: Execution</title>
    <link href="tabs.css" rel="stylesheet" type="text/css" />
    <script type="text/javascript" src="jquery.js"></script>
    <script type="text/javascript" src="dynsections.js"></script>
    <link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript" src="cookie.js"></script>
 <link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
 <script type="text/x-mathjax-config">
MathJax.Hub.Config({
  extensions: ["tex2jax.js"],
  jax: ["input/TeX","output/HTML-CSS"],
});
</script>
<script type="text/javascript" async="async" src="https://cdn.jsdelivr.net/npm/mathjax@2/MathJax.js"></script>
    <link href="doxygen.css" rel="stylesheet" type="text/css" />
    <link href="doxygen-awesome.css" rel="stylesheet" type="text/css"/>
    <!-- ... other metadata & script includes ... -->
    <script type="text/javascript" src="doxygen-awesome-darkmode-toggle.js"></script>
    <script type="text/javascript">
      DoxygenAwesomeDarkModeToggle.init();
    </script>
    <script type="text/javascript" src="doxygen-awesome-fragment-copy-button.js"></script>
    <script type="text/javascript">
      DoxygenAwesomeFragmentCopyButton.init();
    </script>
    <script type="text/javascript" src="doxygen-awesome-paragraph-link.js"></script>
    <script type="text/javascript">
      DoxygenAwesomeParagraphLink.init();
    </script>
    <script type="text/javascript" src="doxygen-awesome-interactive-toc.js"></script>
    <script type="text/javascript">
      DoxygenAwesomeInteractiveToc.init();
    </script>
  </head>
  <body>
      <div id="top">
        <!-- do not remove this div, it is closed by doxygen! -->
        <div id="titlearea">
          <table cellspacing="0" cellpadding="0">
            <tbody>
              <tr id="projectrow">
                <td id="projectalign">
                  <div id="projectname">
                    Iros
                  </div>
                </td>
              </tr>
            </tbody>
          </table>
        </div>
        <!-- end header part -->
<!-- Generated by Doxygen 1.10.0 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function(){initNavTree('md_docs_2di_2execution.html',''); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div><div class="header">
  <div class="headertitle"><div class="title">Execution</div></div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p><a class="anchor" id="autotoc_md21"></a> </p>
<h1><a class="anchor" id="autotoc_md22"></a>
Purpose</h1>
<p>The execution module is designed to allow asynchronous computation in an efficent and composable way. This library uses the design proposed in <a href="https://github.com/brycelelbach/wg21_p2300_execution/tree/main">P2300</a>, except that no execeptions are used.</p>
<h1><a class="anchor" id="autotoc_md23"></a>
Conceptual Overview</h1>
<p>The core component of this library is senders, which represent an asynchronous computation. Senders are composable using provided algorithms, and can their execution can be controlled using schedulers.</p>
<p>Senders can complete in one of three ways:</p>
<ol type="1">
<li>With values</li>
<li>With an error</li>
<li>Stopped (cancellation)</li>
</ol>
<p>This result is communicated to a receiver, which is like a callback that is invoked when the sender completes.</p>
<p>The third concept is a scheduler, which is used to control the execution of a sender. This is used to explicitly model where a sender is executed. For instance, a sender can be executed on a thread pool, or even on a GPU. The scheduler is accessible using the <code><a class="el" href="namespacedi_1_1execution.html#a3b8562510411c44ba43bed9f0eafdac4">di::execution::schedule()</a></code> customization point object (CPO), which produces a sender which completes on the scheduler. Any work chained to this sender will also be executed on the scheduler.</p>
<h2><a class="anchor" id="autotoc_md24"></a>
Life Time Model</h2>
<p>The sender/receiver model obeys structured concurrency, which enables asynchronous operations to be composed safely without any form of garbage collection (or using shared pointers). In fact, a scheduler for Linux's io_uring is capable of scheduling tasks, while performing async io, all without any memory allocations (or even system calls).</p>
<p>They key behind this model is that senders are not started until they are connected to a receiver, and the resulting operation state is explicitly started. The operation state itself is an immovable type which cannot be destroyed until the sender completes (either with a value, error, or stopped). This means that the operation state can be allocated on stack, in cases where the caller waits for the sender to complete. Additionally, the sender itself uses the operation state to store everything needed to complete the computation, which means the sender is free to be destroyed once it is connected to a receiver. The receiver itself will be stored in the operation state, and will be destroyed when the computation completes.</p>
<p>The operation state being immovable is like the <code>Pin&lt;T&gt;</code> type from rust, and is especially useful because it means that the operation states can be stored in a linked-list of stack allocated variables. This enables the sender/receiver model to schedule work without allocating any memory.</p>
<h1><a class="anchor" id="autotoc_md25"></a>
Async Sequences</h1>
<p>An extension to the sender model is the async sequence. This is a sender which itself completes when the entire sequence finishes. Each individual element of the sequence is communicated to the receiver using the <code><a class="el" href="namespacedi_1_1execution.html#a2458c1749fcf4c3a9fe48a55ab8820ba" title="Set the next sender of a sequence.">di::execution::set_next()</a></code> CPO, which is passed an lvalue receiver and a sender which sends the next element of the sequence. This mechanism is modelled after a draft c++ <a href="https://github.com/kirkshoop/sequence-next">standard proposal</a>.</p>
<p>A key aspect of this model is that the outer sender can only complete once all of the inner senders have completed. This ensures structured concurrency, and allows the outer sender to perform cleanup operations once all of the inner senders have completed. Cancellation can prevent new inner senders from being started, but any pending inner senders still must complete before the outer sender can complete.</p>
<h2><a class="anchor" id="autotoc_md26"></a>
Who calls set_next()?</h2>
<p>The <code><a class="el" href="namespacedi_1_1execution.html#a2458c1749fcf4c3a9fe48a55ab8820ba" title="Set the next sender of a sequence.">di::execution::set_next()</a></code> CPO is called by the sequence sender whenever it determines that there is another element in the sequence. For instance, if a sequence sender represents a server listening to sockets, it can call set_next() whenever it makes a request to accept a new socket (i.e. with io_uring). Then this sender completes when the connection is actually established. Some sequences do not need to compute the next element asynchronously, and can provide <code><a class="el" href="namespacedi_1_1execution.html#afd0227de21744a54490113644cf720e1">di::execution::just(values...)</a></code> as the next sender.</p>
<p>Additionally, multiple next senders can be in-flight simultaneously. This is useful for sequences which can compute on multiple threads. Since this is controlled by the sequence itself, sequences can also guarantee that only one next sender is in-flight at a time, which might allow optimizations.</p>
<p>The return value of <code><a class="el" href="namespacedi_1_1execution.html#a2458c1749fcf4c3a9fe48a55ab8820ba" title="Set the next sender of a sequence.">di::execution::set_next()</a></code> is an new sender, which must connected and started. Normally, this is done by the producer itself directly after calling <code>set_next()</code>, which connects the return value to its own receiver. This acts as a hook to fire off more work when that sender finishes. The associated operation state is also normally started immediately. In the case where there is only a single sender in-flight at a time, the operation state can be stored directly, but if there were a dynamic number of senders in-flight, the operation states may need to be heap allocated.</p>
<h2><a class="anchor" id="autotoc_md27"></a>
set_next() Allows the Receiver to Communicate Back to the Sequence</h2>
<p>The <code><a class="el" href="namespacedi_1_1execution.html#a2458c1749fcf4c3a9fe48a55ab8820ba" title="Set the next sender of a sequence.">di::execution::set_next()</a></code> CPO not only informs the receiver of the next element in the sequence, but also returns a sender which the sequence must handle. This sender either completes with a void value, which indicates that the item was accepted, or it completes with <code><a class="el" href="structdi_1_1execution_1_1SetStopped.html">di::execution::SetStopped()</a></code>, which indicates that the sequence should stop sending new elements.</p>
<p>Since this outcome is itself modelled by a sender, it is an asynchronous computation. This allows the receiver to communicate back-pressure to the sequence. For instance, if the sequence is a server which is listening to sockets, the consumer can simply not complete the sender returned by <code>set_next()</code> until it is ready to accept a new socket. Sequences which enforce a maximum number of in-flight next senders can use this mechanism to ensure that the sequence does not start too many next senders.</p>
<h2><a class="anchor" id="autotoc_md28"></a>
Async Sequence Life Time Model</h2>
<p>Like in the case of regular senders, the operation state of an async sequence is immovable, and must not be destroyed before the sequence completes. However, each individual next sender has its own lifetime and associated operation state. The key point is that all of the next senders must complete before the sequence can complete, and the sequence must ensure that the operation states of the next senders are not destroyed before they complete.</p>
<p>In practice, this means that before the final completion can be reported, the sequence must wait for all of the next senders to complete, and then it can destroy the operation states of the next senders. Because next senders can complete in parallel (and on different threads), there is a requirement that the completion of all of the next senders strongly happens before the the sequence can complete. This can be accomplished by having an atomic counter which decrements when a next sender completes, and it is sufficent to use acquire/release memory ordering for this counter.</p>
<p>The upside of this model is that the sequence can be allocated on the stack, and there is never any chance of dangling pointers, since the operation state's have guaranteed lifetimes. The downside is that the sequence must wait for all of the next senders to complete before it can complete, which means that cancelling the sequence actually requires some work. This can also be considered desireable since it ensures that cleanup operations are performed when needed, and not in a distant point in the future when a shared pointer's ref count reaches zero.</p>
<h2><a class="anchor" id="autotoc_md29"></a>
Lockstep Sequences</h2>
<p>Although the model allows for multiple next senders to be in-flight at the same time, in many cases, the underlying sequence ensures that only one next sender is in-flight at a time. This property can be used to optimize algorithms by removing the need for synchronization. For instance, an algorithm like <code>execution::fold()</code>, which can be used to compute the sum of a sequence, needs to ensure the fold function is not called concurrently. If the sequence is a lockstep sequence, no synchronization is needed. Sequences can opt-in to this optimization by providing overriding the query <code><a class="el" href="namespacedi_1_1execution.html#a9901c7da667aac8d8b16c542cce6a708" title="A query that returns whether or not a sequence is always lockstep.">execution::is_always_lockstep_sequence</a></code> to return true in their associated environment.</p>
<p>The library provides the <code><a class="el" href="namespacedi_1_1execution.html#aab707edaa7183d9de7470e063158164a" title="Converts a sequence into a lockstep sequence.">execution::into_lockstep_sequence()</a></code> CPO, which can be used to convert a parallel sequence into a lockstep sequence. This is used internally for any algorithm like <code>execution::fold()</code> which requires a lockstep sequences.</p>
<h2><a class="anchor" id="autotoc_md30"></a>
How do completion signatures work with sequences?</h2>
<p>Since all sequences complete with a call to <code><a class="el" href="namespacedi_1_1execution.html#ad4325f4d43b09dc0cd01e9b559ce1c11">di::execution::set_value()</a></code>, this completion signature is implied. Instead, the reported value completion signatures are the completion signatures of the next sender. The error and stopped signatures can be propogated as the overall result of the sequence, and are also valid completions for the next sender (but the return value from set_next() must transform these errors into a value or stopped completion).</p>
<h2><a class="anchor" id="autotoc_md31"></a>
Comparison with libunifex Models</h2>
<p><a href="https://github.com/facebookexperimental/libunifex">libunifex</a> provides two models for sending multiple values: many sender and async stream.</p>
<p>The many sender model allows senders to complete multiple times, which is useful for parallelism. However, the individual items are not really modelled by an asyncronous process, and there is no way to perform cleanup.</p>
<p>The async stream model is similar to the async sequence model, but it does not allow multiple next senders to be in flight at the same time. This means that the sequence must be able to compute the next element in series, which makes parallelism difficult (but it can be done using queueing). For cleanup, there is an explicit CPO which algorithms need to call, which is not ideal.</p>
<p>Additionally, the async stream is poll-based instead of push-based. This means that someone needs to call <code>next()</code> on stream to get a new element, which is constrasts with regaular senders which push elements to the receiver.</p>
<h2><a class="anchor" id="autotoc_md32"></a>
Drawbacks of the Async Sequence Model</h2>
<p>The main tradeoff of the async sequence model is that since multiple next senders can be in-flight at the same time, there needs to be synchronization in some algorithms. This is also true for the many sender model, in algorithms like <code><a class="el" href="namespacedi_1_1execution.html#a59d4a5552aeddba1c0e1882a482f1ace">di::execution::when_all()</a></code>. But this may be more common in the async sequence model. On the other hand, as long as the synchronization can be done with simple atomics, it should not be a problem.</p>
<p>A serious issue is that if the sequence produces values in line, there will be eventually be stack overflow issues. This can be worked-around by using a queue or scheduler to delay the next sender, but this is not ideal. There are ongoing efforts to add tail senders to P2300, which would solve this issue but bring more complexity.</p>
<h1><a class="anchor" id="autotoc_md33"></a>
Async RAII</h1>
<p>In normal c++, RAII is used to ensure that resources are cleaned up when they go out of scope. However, this model breaks down because of several limitations:</p>
<ol type="1">
<li>Asynchronous operations have 2 scopes: the lexical scope, and the "async" scope of the operation state.</li>
<li>Destructors cannot be asynchronous.</li>
<li>Destructors cannot return errors.</li>
</ol>
<h2><a class="anchor" id="autotoc_md34"></a>
The Async Call Stack</h2>
<p>In the sender receiver model, operations do not start immediately. When a function returns a sender, all of its local variables are destroyed, before the actual sender is started. Imagine the following sender function:</p>
<div class="fragment"><div class="line"><span class="keyword">auto</span> my_sender() {</div>
<div class="line">    <span class="comment">// By the time this function returns, the thread pool will be destroyed, and the scheduler will be invalid.</span></div>
<div class="line">    <span class="keyword">auto</span> my_thread_pool = di::ThreadPool(4);</div>
<div class="line">    <span class="keywordflow">return</span> <a class="code hl_variable" href="namespacedi_1_1execution.html#af0027f43a9c5889062402b45528dce74">di::execution::on</a>(my_thread_pool.get_scheduler(), do_some_work);</div>
<div class="line">}</div>
<div class="ttc" id="anamespacedi_1_1execution_html_af0027f43a9c5889062402b45528dce74"><div class="ttname"><a href="namespacedi_1_1execution.html#af0027f43a9c5889062402b45528dce74">di::execution::on</a></div><div class="ttdeci">constexpr auto on</div><div class="ttdef"><b>Definition</b> on.h:165</div></div>
</div><!-- fragment --><p>Even though sync RAII can cleanup all the threads in the thread pool, its lifetime does not match the lifetime of the asynchronous operation. What's really happening is that the functions which create senders only create a "task graph" which describes what work to do. We can not acquire the resources needed to do the work until the task graph is being executed.</p>
<p>What we want to do instead is create a "node" in the task graph which acquires the resources, and reference that as part of the sender. The actual thread pool object is now stored in the operation state, whose lifetime matches the lifetime of the asynchronous operation.</p>
<h2><a class="anchor" id="autotoc_md35"></a>
Cleanup can be Asynchronous</h2>
<p>The second problem is that destructors cannot be asynchronous. This is a problem because the last thing an asynchronous runtime wants to do is block on a synchronous operation. This holds even for the cleanup of resources. For instance, in the example of the thread pool, we want to wait for all of the threads to finish before we can destroy the thread pool. Technically, we can block in the destructor, but this shuts down all oppurtunities for parallelism. Other operations can run while the threads are being joined, if only we could wait asynchronously. Additionally, we can imagine that if our RAII objects were threads themselves, it would be much better to wait for all of the threads to finish asynchronously in parallel whether than block on each thread one at a time.</p>
<h2><a class="anchor" id="autotoc_md36"></a>
Cleanup can be Fallible</h2>
<p>C++ destructors cannot return errors, which is inconvenient for asynchronous operations. For instance, it turns out that calling join on a thread can fail spuriously (like the kernel is out of memory). Throwing an exception in a destructor is very bad, and this project disables exceptions globally. The best we can do is <a class="el" href="assert__bool_8h.html#af343b20373ba49a92fce523e948f2ab3">ASSERT(false)</a> in the destructor and require the user to call <code>join()</code> manually. This is extremely terrible.</p>
<p>It gets worse when modelling things which are likely to fail, like network connections. When closing a network connection, the operation can fail due to various reasons, like pending data not successfully getting flushed, dropping packets, or an actively malicous peer. Being able to handle errors in these cases is important.</p>
<h2><a class="anchor" id="autotoc_md37"></a>
Async RAII Working Design</h2>
<p>The async RAII model is achieves these goals by modelling a resource as an async sequence which sends a single value when the resource is acquired, and completes when the resource is released. The resource is acquired when the sequence's first item completes, and the resource starts to be released when the sequence's receiver acknowledges the value. Then the sequence completes when the resource is fully released.</p>
<p>This design idea is taken from the <a href="https://kirkshoop.github.io/async_scope/async-resource.html">async resource</a> c++ proposal. The following code example shows a correct use of the async resource model:</p>
<div class="fragment"><div class="line"><span class="keyword">auto</span> my_sender() {</div>
<div class="line">    <span class="keywordflow">return</span> <a class="code hl_variable" href="namespacedi_1_1execution.html#a453eb71b631652bda317f20dd6aa2142">di::execution::use_resources</a>([](<span class="keyword">auto</span> thread_pool_token) {</div>
<div class="line">        <span class="keywordflow">return</span> <a class="code hl_variable" href="namespacedi_1_1execution.html#af0027f43a9c5889062402b45528dce74">di::execution::on</a>(thread_pool.get_scheduler(), do_some_work);</div>
<div class="line">    }, di::make_deferred&lt;di::ThreadPool&gt;(4));</div>
<div class="line">}</div>
<div class="ttc" id="anamespacedi_1_1execution_html_a453eb71b631652bda317f20dd6aa2142"><div class="ttname"><a href="namespacedi_1_1execution.html#a453eb71b631652bda317f20dd6aa2142">di::execution::use_resources</a></div><div class="ttdeci">constexpr auto use_resources</div><div class="ttdoc">Use async resources.</div><div class="ttdef"><b>Definition</b> use_resources.h:56</div></div>
</div><!-- fragment --><p>The <code><a class="el" href="namespacedi_1_1execution.html#a453eb71b631652bda317f20dd6aa2142" title="Use async resources.">execution::use_resources()</a></code> function takes a function which returns a sender, and multiple deferred async resources. In this model, the thread pool's construction is delayed until the sender is started. The sequence does not send the thread pool itself, but instead sends a token which is essentially a reference-wrapper to the thread pool. This is done so that the values can safely be decay copied, without ever moving the thread pool itself. The thread pool is automatically joined after the returned sender completes.</p>
<h2><a class="anchor" id="autotoc_md38"></a>
use_resources() Implementation</h2>
<p>The implementation of <code><a class="el" href="namespacedi_1_1execution.html#a453eb71b631652bda317f20dd6aa2142" title="Use async resources.">execution::use_resources()</a></code> is effectively a combination of a few sequence sender algorithms. It is essentially as follows:</p>
<div class="fragment"><div class="line"><span class="keyword">auto</span> use_resources(<span class="keyword">auto</span> invocable, <span class="keyword">auto</span>&amp;&amp;... deferred_resources) {</div>
<div class="line">    <span class="keywordflow">return</span> <a class="code hl_variable" href="namespacedi_1_1execution.html#a205ba3e1439f9a633846ec4768b07eac">execution::let_value_with</a>([invocable](<span class="keyword">auto</span>&amp; resources) {</div>
<div class="line">        <span class="keywordflow">return</span> <a class="code hl_variable" href="namespacedi_1_1execution.html#a44c87368345e68d8b7342e32cd3b469a">execution::first_value</a>(</div>
<div class="line">            <a class="code hl_variable" href="namespacedi_1_1execution.html#ad70a9cea178eec6ca25e6163042fea06">execution::zip</a>(<a class="code hl_variable" href="namespacedi_1_1execution.html#a28a85fd1939a6e2c9ac31f1150bcd873">execution::run</a>(resources)...)</div>
<div class="line">                | let_value_each(invocable)</div>
<div class="line">        );</div>
<div class="line">    }, deferred_resources...);</div>
<div class="line">}</div>
<div class="ttc" id="anamespacedi_1_1execution_html_a205ba3e1439f9a633846ec4768b07eac"><div class="ttname"><a href="namespacedi_1_1execution.html#a205ba3e1439f9a633846ec4768b07eac">di::execution::let_value_with</a></div><div class="ttdeci">constexpr auto let_value_with</div><div class="ttdoc">Inject values into an operation state.</div><div class="ttdef"><b>Definition</b> let_value_with.h:117</div></div>
<div class="ttc" id="anamespacedi_1_1execution_html_a28a85fd1939a6e2c9ac31f1150bcd873"><div class="ttname"><a href="namespacedi_1_1execution.html#a28a85fd1939a6e2c9ac31f1150bcd873">di::execution::run</a></div><div class="ttdeci">constexpr auto run</div><div class="ttdoc">Obtain access to an async resource.</div><div class="ttdef"><b>Definition</b> run.h:40</div></div>
<div class="ttc" id="anamespacedi_1_1execution_html_a44c87368345e68d8b7342e32cd3b469a"><div class="ttname"><a href="namespacedi_1_1execution.html#a44c87368345e68d8b7342e32cd3b469a">di::execution::first_value</a></div><div class="ttdeci">constexpr auto first_value</div><div class="ttdoc">Transform a sequence into a sender of its first value.</div><div class="ttdef"><b>Definition</b> first_value.h:335</div></div>
<div class="ttc" id="anamespacedi_1_1execution_html_ad70a9cea178eec6ca25e6163042fea06"><div class="ttname"><a href="namespacedi_1_1execution.html#ad70a9cea178eec6ca25e6163042fea06">di::execution::zip</a></div><div class="ttdeci">constexpr auto zip</div><div class="ttdoc">Zip multiple sequences together.</div><div class="ttdef"><b>Definition</b> zip.h:581</div></div>
</div><!-- fragment --><p>The <code><a class="el" href="namespacedi_1_1execution.html#a205ba3e1439f9a633846ec4768b07eac" title="Inject values into an operation state.">execution::let_value_with()</a></code> algorithm allows us to consume the deferred resources by reference, after constructing them in the operation state. The <code><a class="el" href="namespacedi_1_1execution.html#a44c87368345e68d8b7342e32cd3b469a" title="Transform a sequence into a sender of its first value.">execution::first_value()</a></code> algorithm is essentially a no-op, since the sequences only send a single value, but is needed to convert the sequence into a sender. The <code><a class="el" href="namespacedi_1_1execution.html#ad70a9cea178eec6ca25e6163042fea06" title="Zip multiple sequences together.">execution::zip()</a></code> algorithm is used to combine the resources into a single sequence, which the invocable can consume.</p>
<p>The main interesting point is the <code><a class="el" href="namespacedi_1_1execution.html#a28a85fd1939a6e2c9ac31f1150bcd873" title="Obtain access to an async resource.">execution::run()</a></code> CPO, which is used to start the resource sequences. The <code><a class="el" href="namespacedi_1_1execution.html#a28a85fd1939a6e2c9ac31f1150bcd873" title="Obtain access to an async resource.">execution::run()</a></code> CPO is the API which allows something to be an async resource. It takes an lvalue reference to the resource, and returns a sequence sender, as described above.</p>
<h2><a class="anchor" id="autotoc_md39"></a>
make_deferred Implementation</h2>
<p>The <code>di::make_deferred()</code> function is used to create a deferred object. It is essentially defined as follows:</p>
<div class="fragment"><div class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;</div>
<div class="line"><span class="keyword">auto</span> make_deferred(<span class="keyword">auto</span>&amp;&amp; args) {</div>
<div class="line">    <span class="keywordflow">return</span> [args = di::forward&lt;decltype(args)&gt;(args)]() <span class="keyword">mutable</span> {</div>
<div class="line">        <span class="keywordflow">return</span> T(di::move(args));</div>
<div class="line">    };</div>
<div class="line">}</div>
</div><!-- fragment --><p>The returned object is a function which can be invoked to construct the object. <code>T</code> can be immovable thanks to guaranteed RVO. The <code>args</code> are moved into the function, so the returned function is copyable only if all <code>args</code> are copyable.</p>
<p>Since this is the simple model for deferred objects, it is possible to provide arbitrary 0 argument lambdas as input to the <code><a class="el" href="namespacedi_1_1execution.html#a453eb71b631652bda317f20dd6aa2142" title="Use async resources.">execution::use_resources()</a></code> function if necessary. <code>di::make_deferred()</code> is just a convenience function to make this easier.</p>
<h2><a class="anchor" id="autotoc_md40"></a>
Async RAII in Coroutines</h2>
<p>Coroutines allow asynchronous code to be written in c++ without the need for complex template metaprogramming and sender algorithms. However, this async RAII model does not naturally fit into coroutines, unlike other concepts of the sender receiver model. This is because the notion of an async scope does not mirror the lexical scope of a coroutine. For instance:</p>
<div class="fragment"><div class="line"><span class="keyword">auto</span> f() -&gt; di::Lazy&lt;&gt; {</div>
<div class="line">    <span class="keywordflow">for</span> (<span class="keywordtype">int</span> i = 0; i &lt; 10; i++) {</div>
<div class="line">        <span class="comment">// Let&#39;s say this somehow worked.</span></div>
<div class="line">        <span class="keyword">auto</span> thread_pool = <span class="keyword">co_await</span> di::co_use_resource&lt;di::ThreadPool&gt;(4);</div>
<div class="line"> </div>
<div class="line">        <span class="keyword">co_await</span> <a class="code hl_variable" href="namespacedi_1_1execution.html#af0027f43a9c5889062402b45528dce74">di::execution::on</a>(thread_pool.get_scheduler(), do_some_work);</div>
<div class="line"> </div>
<div class="line">        <span class="comment">// At this point, we would expect the thread pool to be destroyed, but it cannot be. Async RAII in coroutines</span></div>
<div class="line">        <span class="comment">// would have to destroy the thread pool only when the coroutine itself is destroyed. So in effect, we would</span></div>
<div class="line">        <span class="comment">// have made 10 thread pools at once.</span></div>
<div class="line">    }</div>
<div class="line">}</div>
</div><!-- fragment --><p>The <code>co_use_resource()</code> function is a hypothetical coroutine version of <code>use_resources()</code>. The problem is that the coroutine is a single node in the task graph, so there is no way to apply the async RAII model in a more granular way. This is particular problematic if anyone tries to use an async mutex, since the mutex would be locked for the entire coroutine. One could easily imagine this leading to deadlock, since the lock is not held for the lexical scope of the variable. Additionally, it is unclear if <code>co_use_resource()</code> could even be implemented in a way which allows more that one resource to be acquired.</p>
<p>The solution is to just call the <code>use_resources()</code> function from within the coroutine, and then immediately co_await the result. This is not ideal, because it is more verbose, and importantly, is unworkable if we need to call <code>co_yield</code> in the coroutine. These things can be probably be worked around, but it will be increasingly difficult to do so.</p>
<h1><a class="anchor" id="autotoc_md41"></a>
Async Scope</h1>
<p>A key aspect of structured concurrency is "scoping" groups of asynchronous operations into a single group. Before the "outer" operation completes, all "inner" operations must complete. This additionally allows requesting cancellation of the entire group of operations, and manages the memory and lifetime of the operations.</p>
<p>The library provides 3 CPOs for interacting with async scopes:</p>
<ol type="1">
<li><code><a class="el" href="namespacedi_1_1execution.html#ac79c57f100fce9f000b54d4b5d4db498" title="Nest a sender inside a scope.">execution::nest()</a></code></li>
<li><code><a class="el" href="namespacedi_1_1execution.html#a2cbdc8590257091c72345c9d73fdd262" title="Spawn a sender inside a scope.">execution::spawn()</a></code></li>
<li><code><a class="el" href="namespacedi_1_1execution.html#a9f91f698e51a9c7a9479c769e7aa69b3" title="Spawn a sender inside a scope, and return a future to the result.">execution::spawn_future()</a></code></li>
</ol>
<h2><a class="anchor" id="autotoc_md42"></a>
Nest</h2>
<p>The <code><a class="el" href="namespacedi_1_1execution.html#ac79c57f100fce9f000b54d4b5d4db498" title="Nest a sender inside a scope.">execution::nest()</a></code> CPO is used to wrap a sender in an async scope. It takes a sender, and returns a new sender which signals the completion of the original sender to the async scope. This allows the scope to know when all of its operations have completed.</p>
<h2><a class="anchor" id="autotoc_md43"></a>
Spawn</h2>
<p>The <code><a class="el" href="namespacedi_1_1execution.html#a2cbdc8590257091c72345c9d73fdd262" title="Spawn a sender inside a scope.">execution::spawn()</a></code> CPO is used to spawn a task, without waiting for it to complete. It takes a sender, and runs it in the provided async scope. The operation's lifetime is fully managed by the async scope, and it automatically deleted when the operation completes. And like <code><a class="el" href="namespacedi_1_1execution.html#ac79c57f100fce9f000b54d4b5d4db498" title="Nest a sender inside a scope.">execution::nest()</a></code>, it signals the completion of the operation to the async scope so it can track when all operations have completed.</p>
<h2><a class="anchor" id="autotoc_md44"></a>
Spawn Future</h2>
<p>The <code><a class="el" href="namespacedi_1_1execution.html#a9f91f698e51a9c7a9479c769e7aa69b3" title="Spawn a sender inside a scope, and return a future to the result.">execution::spawn_future()</a></code> CPO is used to spawn a task, and return a future which has the values which the task sends. It takes a sender, and runs it in the provided async scope. The operation's lifetime is fully managed by the async scope, and it automatically deleted when the operation completes. And like <code><a class="el" href="namespacedi_1_1execution.html#ac79c57f100fce9f000b54d4b5d4db498" title="Nest a sender inside a scope.">execution::nest()</a></code>, it signals the completion of the operation to the async scope so it can track when all operations have completed. The difference between this function and <code><a class="el" href="namespacedi_1_1execution.html#a2cbdc8590257091c72345c9d73fdd262" title="Spawn a sender inside a scope.">execution::spawn()</a></code> is that this function returns a future which can be used to retrieve the values, and thus requires more synchronization and memory overhead.</p>
<h2><a class="anchor" id="autotoc_md45"></a>
Counting Scope</h2>
<p>The <code>di::CountingScope</code> class template is a concrete implementation of an async scope. It is modelled as an async resource, and can be used with the <code><a class="el" href="namespacedi_1_1execution.html#a453eb71b631652bda317f20dd6aa2142" title="Use async resources.">execution::use_resources()</a></code> function. It is a counting scope, meaning it tracks the number of operations which have been spawned, and signals completion when all operations have completed. Since it is an async resource, this is done automatically when the resource is destroyed.</p>
<div class="fragment"><div class="line"><span class="keyword">auto</span> spawn_sender = <a class="code hl_variable" href="namespacedi_1_1execution.html#a453eb71b631652bda317f20dd6aa2142">execution::use_resources</a>(</div>
<div class="line">    [&amp;](<span class="keyword">auto</span> scope, <span class="keyword">auto</span> pool) {</div>
<div class="line">        <span class="comment">// Do 10 things in parallel on the thread pool.</span></div>
<div class="line">        <span class="keywordflow">for</span> (<span class="keywordtype">int</span> i = 0; i &lt; 10; i++) {</div>
<div class="line">            <a class="code hl_variable" href="namespacedi_1_1execution.html#a2cbdc8590257091c72345c9d73fdd262">execution::spawn</a>(scope, <a class="code hl_variable" href="namespacedi_1_1execution.html#af0027f43a9c5889062402b45528dce74">execution::on</a>(pool, do_some_work));</div>
<div class="line">        }</div>
<div class="line">        <span class="keywordflow">return</span> <a class="code hl_variable" href="namespacedi_1_1execution.html#afd0227de21744a54490113644cf720e1">execution::just</a>();</div>
<div class="line">    },</div>
<div class="line">    di::make_deferred&lt;di::CountingScope&lt;&gt;&gt;(), di::make_deferred&lt;di::ThreadPool&gt;());</div>
<div class="ttc" id="anamespacedi_1_1execution_html_a2cbdc8590257091c72345c9d73fdd262"><div class="ttname"><a href="namespacedi_1_1execution.html#a2cbdc8590257091c72345c9d73fdd262">di::execution::spawn</a></div><div class="ttdeci">constexpr auto spawn</div><div class="ttdoc">Spawn a sender inside a scope.</div><div class="ttdef"><b>Definition</b> scope.h:129</div></div>
<div class="ttc" id="anamespacedi_1_1execution_html_afd0227de21744a54490113644cf720e1"><div class="ttname"><a href="namespacedi_1_1execution.html#afd0227de21744a54490113644cf720e1">di::execution::just</a></div><div class="ttdeci">constexpr auto just</div><div class="ttdef"><b>Definition</b> just.h:86</div></div>
</div><!-- fragment --><p>The async resource mechanism ensures that the waiting for the completion of the scope is done automatically, and also enables a simple implementation.</p>
<h2><a class="anchor" id="autotoc_md46"></a>
Benefits of Async Scope Abstraction</h2>
<p>In the above example, the <code>CountingScope</code> is used to track the number of operations which have been spawned. This enables spawning a dynamic number of operations, and waiting for them to complete. This is not possible with the <code><a class="el" href="namespacedi_1_1execution.html#a59d4a5552aeddba1c0e1882a482f1ace">execution::when_all()</a></code> function, since it is passed senders to wait for in parallel. This means the number of senders must be known at compile time.</p>
<p>The async scope mechanism enables spawning tasks with regular loops and control flow, while still enabling the parallel execution of the tasks, as well as waiting for them to complete. As such, it is a more natural fit for many use cases.</p>
<p>Some other examples where an async scope is useful:</p>
<ul>
<li>Spawning a task for each file in a directory, and waiting for them all to complete.</li>
<li>Spawning a task for each request made to the Iris kernel, which scoping all operations to a specific process.</li>
<li>Creating an async sequence which sends a values in parallel, and thus needs to spawn a task for each value.</li>
<li>Conditionally spawning a task, depending on whether each value in a range is "interesting".</li>
</ul>
<h1><a class="anchor" id="autotoc_md47"></a>
Type Erased Sender</h1>
<p>The <code>di::AnySender</code> class template is a type erased sender, meaning it can hold any sender that satisfies the requirements.</p>
<div class="fragment"><div class="line"><span class="comment">// This is a type erased sender that can hold any sender that can complete with exactly an i32.</span></div>
<div class="line"><span class="keyword">using </span>MySender = di::AnySender&lt;</div>
<div class="line">    <a class="code hl_struct" href="structdi_1_1types_1_1CompletionSignatures.html">di::CompletionSignatures</a>&lt;<a class="code hl_struct" href="structdi_1_1execution_1_1SetValue.html">di::SetValue</a>(i32)&gt;</div>
<div class="line">&gt;;</div>
<div class="line"> </div>
<div class="line"><span class="keyword">auto</span> x = MySender(di::just(5));</div>
<div class="line"><span class="keyword">auto</span> y = MySender(next_keyboard_scan_code());</div>
<div class="ttc" id="astructdi_1_1execution_1_1SetValue_html"><div class="ttname"><a href="structdi_1_1execution_1_1SetValue.html">di::execution::SetValue</a></div><div class="ttdef"><b>Definition</b> set_value.h:6</div></div>
<div class="ttc" id="astructdi_1_1types_1_1CompletionSignatures_html"><div class="ttname"><a href="structdi_1_1types_1_1CompletionSignatures.html">di::types::CompletionSignatures</a></div><div class="ttdef"><b>Definition</b> completion_signuatures.h:7</div></div>
</div><!-- fragment --><div class="fragment"><div class="line"><span class="comment">// This is a type erased sender that can hold any sender that can complete with an i32, void, or an error.</span></div>
<div class="line"><span class="keyword">using </span>MySender = di::AnySender&lt;</div>
<div class="line">    <a class="code hl_struct" href="structdi_1_1types_1_1CompletionSignatures.html">di::CompletionSignatures</a>&lt;<a class="code hl_struct" href="structdi_1_1execution_1_1SetValue.html">di::SetValue</a>(i32), <a class="code hl_struct" href="structdi_1_1execution_1_1SetValue.html">di::SetValue</a>(), <a class="code hl_struct" href="structdi_1_1execution_1_1SetError.html">di::SetError</a>(di::Error)&gt;;</div>
<div class="line"> </div>
<div class="line"><span class="keyword">auto</span> x = MySender(di::just(5));</div>
<div class="line"><span class="keyword">auto</span> y = MySender(di::just());</div>
<div class="line"><span class="keyword">auto</span> z = MySender(di::just_error(di::Error(di::BasicError::InvalidArgument)));</div>
<div class="ttc" id="astructdi_1_1execution_1_1SetError_html"><div class="ttname"><a href="structdi_1_1execution_1_1SetError.html">di::execution::SetError</a></div><div class="ttdef"><b>Definition</b> set_error.h:6</div></div>
</div><!-- fragment --><p>The key point is that AnySender can hold any sender that can complete with a strict subset of the allowed signatures.</p>
<h2><a class="anchor" id="autotoc_md48"></a>
How does this work?</h2>
<p>A key aspect of this model is that senders can connect to any receiver which accepts its completion signature. This normally results in a lot of templates, which cannot be represented in a type erased context. To solve this, there is also a type erased receiver, which can hold any receiver that accepts the completion signature of the sender.</p>
<p>Furthermore, the result of connecting a sender to a receiver is an operation state, which will also be different for each sender-receiver pair. There is therefore also a type-erased operation state.</p>
<p>Lastly, senders, receivers, and operation states are all queryable, and the resulting environment object must also be type-erased.</p>
<h2><a class="anchor" id="autotoc_md49"></a>
Problems with this Approach</h2>
<p>The main problem with this approach is that it will require heap-allocations for sufficently large senders, receivers, and operation states. What's more, allocations can fail, and the library does not allow throwing exceptions. This creates a problem, because the <code>di::connect</code> CPO is required to return a valid operation state, and this may require a heap allocation.</p>
<h3><a class="anchor" id="autotoc_md50"></a>
Case 1: Creating the Type-Erased Receiver Fails</h3>
<p>There is really no choice but to simply refuse to compile code if the type-erased receiver conversion is fallible. The only potential alternative would be to immediately invoke the receiver with an error, but this could cause asyncrhonous computations to start before the operation state is started, which breaks the entire model. Luckily, receivers can always be implemented as storing a single pointer (to an operation state or stack variable), so this is not a problem.</p>
<h3><a class="anchor" id="autotoc_md51"></a>
Case 2: Creating the Type-Erased Sender Fails</h3>
<p>This too is not really a problem. The <code>di::connect</code> CPO will be called with the type-erased sender already existing, so there is no way for this to fail. However, creating the sender in the first place could fail. This implies that functions returning a type-erased sender would have to return a <code>di::Result&lt;di::AnySender&lt;...&gt;&gt;</code>, which is not ideal, especially since this model already encompasses errors. It would be a lot better to simply return a <code>di::AnySender&lt;...&gt;</code>, and have the error be communicated through the operation state. This is possible, but it requires making <code>di::Expected&lt;Sender, E&gt;</code> a valid sender, with completion signatures equivalent to <code>Sender</code> with the addition of <code>di::SetError(E)</code>. This is not ideal, because it would also mean that this type would need some variant <code>connect</code> function would return a variant operation state, which either holds the operation state of the sender, or the error.</p>
<p>A simpler approach is to add an implicit conversion between any valid <code>Sender</code> and <code>di::AnySender&lt;...&gt;</code>, which first tries to create the type-erased sender, and if that fails, returns it instead returns <code><a class="el" href="namespacedi_1_1execution.html#a3b26457a62e1f788c51d33b0c5cc1215">di::execution::just_error(E)</a></code>. Since this error sender is simple, it can be created without heap allocation, and so the conversion function will always return a valid sender.</p>
<h3><a class="anchor" id="autotoc_md52"></a>
Case 3: Creating the Type-Erased Operation State Fails</h3>
<p>This is the most difficult case to deal with. The problem is that the <code>di::connect</code> CPO is required to return a valid operation state, and may require a heap allocation. The only way to "fix" this is to make a dummy operation state, which when started, immediately invokes the receiver with an error.</p>
<p>The good news is that this can be solved because the <code>di::connect</code> CPO is returning a type-erased operation state. Like in the sender case, this can be done by adding a conversion function between <code>OperationState</code> and <code>di::AnyOperationState&lt;...&gt;</code>. This function will first try to create the type-erased operation state, and if that fails, it will return a dummy operation state which completes with an error once started.</p>
<p>One thing to worry about is that <code>OperationState</code> objects are not movable, so the library must take care to ensure that copy-ellision is used. Additionally, the <code>di::AnyReceiver&lt;...&gt;</code> type will be move-only, so it cannot be stored in both the original operation state and the dummy operation state. This is solvable using the fact that the creation of the type-erased operation state only fails when allocating memory fails. This means that when trying to type-erase the normal operation state, the library can first try to allocate memory for the type-erased receiver, and if that fails, the actual <code>di::connect</code> function will never be called between the sender and receiver. Instead, the dummy operation will be returned. This dummy operation state will be equivalent to the result of connecting <code><a class="el" href="namespacedi_1_1execution.html#a3b26457a62e1f788c51d33b0c5cc1215">di::execution::just_error(E)</a></code> to the type-erased receiver.</p>
<p>The current implementation requires type-erased operation states to be movable to be stored in the inline storage, which is very unfortunate. This is because c++ does not guarantee copy-elision of named return values. As a consequence, the current implementation, which uses the <code>emplace()</code> method of <code>di::Any</code> to perform this two-pass construction, requires the type to be movable. This is really bad, since it greatly increases the number of heap allocations required. The good news is that this decision is transparent to users of the library, since heap allocation failures are already handled transparently by resulting in an error.</p>
<p>This limitation can be resolved by either waiting for the standard to guarantee NRVO, or by using a work-around two-phase construction mechanism that only relies on RVO. This would work by having a static method of <code>di::Any</code> which creates some sort of token object, which proves the required memory is allocated and so construction can be infallible. Another approach that could be considered is creating dummy move operations which assert that they are never called. If the compiler is going to perform NRVO anyway, then these dummy move operations will never be called (maybe...), and since operation states are internal to the library, this might even be safe. This is the simplest approach although it is probably the worst idea in terms of safety.</p>
<h1><a class="anchor" id="autotoc_md53"></a>
References</h1>
<ul>
<li><a href="https://wg21.link/p2300">P2300 - std::execution</a></li>
<li><a href="https://github.com/NVIDIA/stdexec">P2300 Reference Implementation</a></li>
<li><a href="https://github.com/kirkshoop/sequence-next">Sequence Senders</a></li>
<li><a href="https://kirkshoop.github.io/async_scope/async-resource.html">Async Resources</a></li>
<li><a href="https://github.com/facebookexperimental/libunifex/">libunifex</a></li>
<li><a href="https://vorpus.org/blog/notes-on-structured-concurrency-or-go-statement-considered-harmful/">NJS's Blog on Structured Concurrency</a> </li>
</ul>
</div></div><!-- contents -->
</div><!-- PageDoc -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><a class="el" href="index.html">Iros Project Documentation</a></li><li class="navelem"><a class="el" href="md_docs_2di_2table__of__contents.html">Di Library Documentation</a></li>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.10.0 </li>
  </ul>
</div>
</body>
</html>
